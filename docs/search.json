[
  {
    "objectID": "notebook.html",
    "href": "notebook.html",
    "title": "Análise de Correspondência - Consolidação de Estatísticas de Futebol",
    "section": "",
    "text": "Este notebook consolida todas as estatísticas de jogadores e times para preparar dados para análise de correspondência."
  },
  {
    "objectID": "notebook.html#objetivos",
    "href": "notebook.html#objetivos",
    "title": "Análise de Correspondência - Consolidação de Estatísticas de Futebol",
    "section": "Objetivos:",
    "text": "Objetivos:\n\nConsolidar estatísticas por jogador (removendo duplicatas)\nAgregar estatísticas por time\nCriar tabela fato para análise de correspondência\nExportar todas as tabelas como CSV\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configurações de exibição\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_rows', 20)\n\nprint(\"Bibliotecas carregadas com sucesso!\")\n\nBibliotecas carregadas com sucesso!"
  },
  {
    "objectID": "notebook.html#carregamento-e-análise-dos-dados",
    "href": "notebook.html#carregamento-e-análise-dos-dados",
    "title": "Análise de Correspondência - Consolidação de Estatísticas de Futebol",
    "section": "1. Carregamento e Análise dos Dados",
    "text": "1. Carregamento e Análise dos Dados\nPrimeiro vamos carregar todas as tabelas e analisar sua estrutura.\n\n# Carregando todos os datasets\nsumario = pd.read_csv('sumario_jogo.csv')\npassing = pd.read_csv('players_passing_stats.csv')\noffensive = pd.read_csv('players_offensive_stats.csv')\ndefensive = pd.read_csv('players_defensive_stats.csv')\n\n# Informações básicas dos datasets\ndatasets = {\n    'Sumário do Jogo': sumario,\n    'Estatísticas de Passe': passing,\n    'Estatísticas Ofensivas': offensive,\n    'Estatísticas Defensivas': defensive\n}\n\nprint(\"=== INFORMAÇÕES DOS DATASETS ===\")\nfor nome, df in datasets.items():\n    print(f\"\\n{nome}:\")\n    print(f\"  - Dimensões: {df.shape}\")\n    print(f\"  - Jogadores únicos: {df['Player'].nunique()}\")\n    print(f\"  - Times: {df['Team'].unique()}\")\n\n=== INFORMAÇÕES DOS DATASETS ===\n\nSumário do Jogo:\n  - Dimensões: (31, 11)\n  - Jogadores únicos: 31\n  - Times: ['Inter' 'Fluminense']\n\nEstatísticas de Passe:\n  - Dimensões: (31, 14)\n  - Jogadores únicos: 31\n  - Times: ['Inter' 'Fluminense']\n\nEstatísticas Ofensivas:\n  - Dimensões: (31, 13)\n  - Jogadores únicos: 31\n  - Times: ['Inter' 'Fluminense']\n\nEstatísticas Defensivas:\n  - Dimensões: (31, 10)\n  - Jogadores únicos: 31\n  - Times: ['Inter' 'Fluminense']\n\n\n\n# Analisando colunas de cada dataset\nprint(\"=== COLUNAS POR DATASET ===\")\nfor nome, df in datasets.items():\n    print(f\"\\n{nome}:\")\n    print(f\"  Colunas: {list(df.columns)}\")\n\n=== COLUNAS POR DATASET ===\n\nSumário do Jogo:\n  Colunas: ['Player', 'Age', 'Position', 'Shots', 'ShotsOT', 'KeyPasses', 'PA%', 'AerialsWon', 'Touches', 'Rating', 'Team']\n\nEstatísticas de Passe:\n  Colunas: ['Player', 'Age', 'Position', 'KeyPasses', 'Passes', 'PA%', 'Crosses', 'AccCrosses', 'LongBalls', 'AccLongBalls', 'ThroughBalls', 'AccThroughBalls', 'Rating', 'Team']\n\nEstatísticas Ofensivas:\n  Colunas: ['Player', 'Age', 'Position', 'Shots', 'ShotsOT', 'KeyPasses', 'Dribbles', 'Fouled', 'Offsides', 'Dispossessed', 'UnsuccessfulTouches', 'Rating', 'Team']\n\nEstatísticas Defensivas:\n  Colunas: ['Player', 'Age', 'Position', 'TotalTackles', 'Interceptions', 'Clearances', 'BlockedShots', 'Fouls', 'Rating', 'Team']"
  },
  {
    "objectID": "notebook.html#identificação-de-colunas-duplicadas",
    "href": "notebook.html#identificação-de-colunas-duplicadas",
    "title": "Análise de Correspondência - Consolidação de Estatísticas de Futebol",
    "section": "2. Identificação de Colunas Duplicadas",
    "text": "2. Identificação de Colunas Duplicadas\nVamos identificar quais colunas aparecem em múltiplos datasets.\n\n# Identificando colunas comuns entre datasets\nall_columns = {}\nfor nome, df in datasets.items():\n    all_columns[nome] = set(df.columns)\n\n# Colunas que aparecem em múltiplos datasets\ncolunas_duplicadas = {}\nfor col in sumario.columns:\n    datasets_com_coluna = []\n    for nome, colunas in all_columns.items():\n        if col in colunas:\n            datasets_com_coluna.append(nome)\n\n    if len(datasets_com_coluna) &gt; 1:\n        colunas_duplicadas[col] = datasets_com_coluna\n\nprint(\"=== COLUNAS DUPLICADAS ===\")\nfor col, datasets_list in colunas_duplicadas.items():\n    print(f\"{col}: {datasets_list}\")\n\n=== COLUNAS DUPLICADAS ===\nPlayer: ['Sumário do Jogo', 'Estatísticas de Passe', 'Estatísticas Ofensivas', 'Estatísticas Defensivas']\nAge: ['Sumário do Jogo', 'Estatísticas de Passe', 'Estatísticas Ofensivas', 'Estatísticas Defensivas']\nPosition: ['Sumário do Jogo', 'Estatísticas de Passe', 'Estatísticas Ofensivas', 'Estatísticas Defensivas']\nShots: ['Sumário do Jogo', 'Estatísticas Ofensivas']\nShotsOT: ['Sumário do Jogo', 'Estatísticas Ofensivas']\nKeyPasses: ['Sumário do Jogo', 'Estatísticas de Passe', 'Estatísticas Ofensivas']\nPA%: ['Sumário do Jogo', 'Estatísticas de Passe']\nRating: ['Sumário do Jogo', 'Estatísticas de Passe', 'Estatísticas Ofensivas', 'Estatísticas Defensivas']\nTeam: ['Sumário do Jogo', 'Estatísticas de Passe', 'Estatísticas Ofensivas', 'Estatísticas Defensivas']\n\n\n\n# Verificando se os valores das colunas duplicadas são consistentes\nprint(\"=== VERIFICAÇÃO DE CONSISTÊNCIA ===\")\n\n# Verificando KeyPasses (aparece em sumario, passing e offensive)\nif 'KeyPasses' in colunas_duplicadas:\n    print(\"\\nVerificando KeyPasses:\")\n    # Merge para comparar\n    temp_merge = sumario[['Player', 'KeyPasses']].merge(\n        passing[['Player', 'KeyPasses']], on='Player', suffixes=('_sumario', '_passing')\n    )\n    temp_merge = temp_merge.merge(\n        offensive[['Player', 'KeyPasses']], on='Player'\n    )\n    temp_merge.rename(\n        columns={'KeyPasses': 'KeyPasses_offensive'}, inplace=True)\n\n    # Verificando diferenças\n    diff1 = (temp_merge['KeyPasses_sumario'] !=\n             temp_merge['KeyPasses_passing']).sum()\n    diff2 = (temp_merge['KeyPasses_sumario'] !=\n             temp_merge['KeyPasses_offensive']).sum()\n\n    print(f\"  Diferenças sumario vs passing: {diff1}\")\n    print(f\"  Diferenças sumario vs offensive: {diff2}\")\n\n    if diff1 == 0 and diff2 == 0:\n        print(\"  ✓ KeyPasses é consistente entre todos os datasets\")\n    else:\n        print(\"  ⚠ KeyPasses tem diferenças entre datasets\")\n\n=== VERIFICAÇÃO DE CONSISTÊNCIA ===\n\nVerificando KeyPasses:\n  Diferenças sumario vs passing: 0\n  Diferenças sumario vs offensive: 0\n  ✓ KeyPasses é consistente entre todos os datasets"
  },
  {
    "objectID": "notebook.html#consolidação-da-tabela-de-jogadores",
    "href": "notebook.html#consolidação-da-tabela-de-jogadores",
    "title": "Análise de Correspondência - Consolidação de Estatísticas de Futebol",
    "section": "3. Consolidação da Tabela de Jogadores",
    "text": "3. Consolidação da Tabela de Jogadores\nVamos consolidar todas as estatísticas em uma única tabela por jogador, removendo duplicatas.\n\n# Definindo colunas de identificação que devem ser mantidas apenas uma vez\ncolunas_identificacao = ['Player', 'Age', 'Position', 'Team', 'Rating']\n\n# Começando com o sumário como base\nestatisticas_jogadores = sumario.copy()\n\nprint(\"=== PROCESSO DE CONSOLIDAÇÃO ===\")\nprint(f\"Base inicial (sumário): {estatisticas_jogadores.shape}\")\n\n# Adicionando colunas únicas de passing\ncolunas_passing_unicas = [col for col in passing.columns\n                          if col not in estatisticas_jogadores.columns or col == 'Player']\n\nif len(colunas_passing_unicas) &gt; 1:  # Mais que apenas 'Player'\n    passing_unicas = passing[colunas_passing_unicas]\n    estatisticas_jogadores = estatisticas_jogadores.merge(\n        passing_unicas, on='Player', how='left'\n    )\n    print(f\"Após adicionar passing: {estatisticas_jogadores.shape}\")\n    print(\n        f\"Colunas adicionadas de passing: {[col for col in colunas_passing_unicas if col != 'Player']}\")\n\n# Adicionando colunas únicas de offensive\ncolunas_offensive_unicas = [col for col in offensive.columns\n                            if col not in estatisticas_jogadores.columns or col == 'Player']\n\nif len(colunas_offensive_unicas) &gt; 1:\n    offensive_unicas = offensive[colunas_offensive_unicas]\n    estatisticas_jogadores = estatisticas_jogadores.merge(\n        offensive_unicas, on='Player', how='left'\n    )\n    print(f\"Após adicionar offensive: {estatisticas_jogadores.shape}\")\n    print(\n        f\"Colunas adicionadas de offensive: {[col for col in colunas_offensive_unicas if col != 'Player']}\")\n\n# Adicionando colunas únicas de defensive\ncolunas_defensive_unicas = [col for col in defensive.columns\n                            if col not in estatisticas_jogadores.columns or col == 'Player']\n\nif len(colunas_defensive_unicas) &gt; 1:\n    defensive_unicas = defensive[colunas_defensive_unicas]\n    estatisticas_jogadores = estatisticas_jogadores.merge(\n        defensive_unicas, on='Player', how='left'\n    )\n    print(f\"Após adicionar defensive: {estatisticas_jogadores.shape}\")\n    print(\n        f\"Colunas adicionadas de defensive: {[col for col in colunas_defensive_unicas if col != 'Player']}\")\n\nprint(f\"\\nTabela consolidada final: {estatisticas_jogadores.shape}\")\n\n=== PROCESSO DE CONSOLIDAÇÃO ===\nBase inicial (sumário): (31, 11)\nApós adicionar passing: (31, 18)\nColunas adicionadas de passing: ['Passes', 'Crosses', 'AccCrosses', 'LongBalls', 'AccLongBalls', 'ThroughBalls', 'AccThroughBalls']\nApós adicionar offensive: (31, 23)\nColunas adicionadas de offensive: ['Dribbles', 'Fouled', 'Offsides', 'Dispossessed', 'UnsuccessfulTouches']\nApós adicionar defensive: (31, 28)\nColunas adicionadas de defensive: ['TotalTackles', 'Interceptions', 'Clearances', 'BlockedShots', 'Fouls']\n\nTabela consolidada final: (31, 28)\n\n\n\n# Visualizando a tabela consolidada\nprint(\"=== TABELA CONSOLIDADA DE JOGADORES ===\")\nprint(f\"Colunas finais ({len(estatisticas_jogadores.columns)}):\")\nfor i, col in enumerate(estatisticas_jogadores.columns, 1):\n    print(f\"{i:2d}. {col}\")\n\nprint(f\"\\nPrimeiras 3 linhas:\")\nprint(estatisticas_jogadores.head(3))\n\n=== TABELA CONSOLIDADA DE JOGADORES ===\nColunas finais (28):\n 1. Player\n 2. Age\n 3. Position\n 4. Shots\n 5. ShotsOT\n 6. KeyPasses\n 7. PA%\n 8. AerialsWon\n 9. Touches\n10. Rating\n11. Team\n12. Passes\n13. Crosses\n14. AccCrosses\n15. LongBalls\n16. AccLongBalls\n17. ThroughBalls\n18. AccThroughBalls\n19. Dribbles\n20. Fouled\n21. Offsides\n22. Dispossessed\n23. UnsuccessfulTouches\n24. TotalTackles\n25. Interceptions\n26. Clearances\n27. BlockedShots\n28. Fouls\n\nPrimeiras 3 linhas:\n               Player  Age Position  Shots  ShotsOT  KeyPasses   PA%  \\\n0         Yann Sommer   36       GK      0        0          0  96.4   \n1      Matteo Darmian   35       DC      0        0          0  87.5   \n2  Alessandro Bastoni   26       DC      0        0          0  84.0   \n\n   AerialsWon  Touches  Rating   Team  Passes  Crosses  AccCrosses  LongBalls  \\\n0           0       32    5.22  Inter      28        0           0          2   \n1           2       58    6.24  Inter      40        2           1          3   \n2           2       64    6.03  Inter      50        1           0          6   \n\n   AccLongBalls  ThroughBalls  AccThroughBalls  Dribbles  Fouled  Offsides  \\\n0             1             0                0         0       0         0   \n1             1             0                0         0       2         0   \n2             3             1                0         0       0         0   \n\n   Dispossessed  UnsuccessfulTouches  TotalTackles  Interceptions  Clearances  \\\n0             0                    0             0              0           0   \n1             1                    0             2              1           0   \n2             0                    0             0              1           0   \n\n   BlockedShots  Fouls  \n0             0      0  \n1             0      3  \n2             1      2  \n\n\n\n# Salvando tabela consolidada de jogadores\nestatisticas_jogadores.to_csv(\n    'estatisticas_jogadores_consolidada.csv', index=False)\nprint(\"✓ Tabela consolidada de jogadores salva como 'estatisticas_jogadores_consolidada.csv'\")\n\n# Verificando valores faltantes\nprint(f\"\\nValores faltantes por coluna:\")\nmissing_values = estatisticas_jogadores.isnull().sum()\nif missing_values.sum() &gt; 0:\n    print(missing_values[missing_values &gt; 0])\nelse:\n    print(\"Nenhum valor faltante encontrado!\")\n\n✓ Tabela consolidada de jogadores salva como 'estatisticas_jogadores_consolidada.csv'\n\nValores faltantes por coluna:\nNenhum valor faltante encontrado!"
  },
  {
    "objectID": "notebook.html#agregação-por-time",
    "href": "notebook.html#agregação-por-time",
    "title": "Análise de Correspondência - Consolidação de Estatísticas de Futebol",
    "section": "4. Agregação por Time",
    "text": "4. Agregação por Time\nAgora vamos criar estatísticas agregadas por time.\n\n# Identificando colunas numéricas para agregação\ncolunas_numericas = estatisticas_jogadores.select_dtypes(\n    include=[np.number]).columns.tolist()\n\n# Colunas que precisam de tratamento especial\ncolunas_especiais = {\n    'Age': 'mean',        # Idade média\n    'Rating': 'mean',     # Rating médio\n    'PA%': 'mean'         # Porcentagem de passes média\n}\n\n# Colunas para somar (estatísticas de jogo)\ncolunas_soma = [\n    col for col in colunas_numericas if col not in colunas_especiais.keys()]\n\nprint(\"=== ESTRATÉGIA DE AGREGAÇÃO ===\")\nprint(f\"Colunas para média: {list(colunas_especiais.keys())}\")\nprint(f\"Colunas para soma: {colunas_soma}\")\n\n=== ESTRATÉGIA DE AGREGAÇÃO ===\nColunas para média: ['Age', 'Rating', 'PA%']\nColunas para soma: ['Shots', 'ShotsOT', 'KeyPasses', 'AerialsWon', 'Touches', 'Passes', 'Crosses', 'AccCrosses', 'LongBalls', 'AccLongBalls', 'ThroughBalls', 'AccThroughBalls', 'Dribbles', 'Fouled', 'Offsides', 'Dispossessed', 'UnsuccessfulTouches', 'TotalTackles', 'Interceptions', 'Clearances', 'BlockedShots', 'Fouls']\n\n\n\n# Criando agregações por time\nagregacoes = {\n    'Player': 'count',  # Número de jogadores\n}\n\n# Adicionando agregações especiais\nagregacoes.update(colunas_especiais)\n\n# Adicionando somas\nfor col in colunas_soma:\n    agregacoes[col] = 'sum'\n\n# Aplicando agregações\nestatisticas_times = estatisticas_jogadores.groupby(\n    'Team').agg(agregacoes).round(2)\n\n# Renomeando colunas para clareza\nestatisticas_times.rename(columns={\n    'Player': 'NumJogadores',\n    'Age': 'IdadeMedia',\n    'Rating': 'RatingMedio'\n}, inplace=True)\n\nprint(\"=== ESTATÍSTICAS POR TIME ===\")\nprint(f\"Dimensões: {estatisticas_times.shape}\")\nprint(f\"\\nTabela de estatísticas por time:\")\nprint(estatisticas_times)\n\n=== ESTATÍSTICAS POR TIME ===\nDimensões: (2, 26)\n\nTabela de estatísticas por time:\n            NumJogadores  IdadeMedia  RatingMedio    PA%  Shots  ShotsOT  \\\nTeam                                                                       \nFluminense            15       30.67         6.92  63.36     11        4   \nInter                 16       27.44         6.24  86.02     16        4   \n\n            KeyPasses  AerialsWon  Touches  Passes  Crosses  AccCrosses  \\\nTeam                                                                      \nFluminense          7          10      444     240        8           4   \nInter              11          18      689     507       27           5   \n\n            LongBalls  AccLongBalls  ThroughBalls  AccThroughBalls  Dribbles  \\\nTeam                                                                           \nFluminense         47            17             0                0         4   \nInter              35            22             2                0         6   \n\n            Fouled  Offsides  Dispossessed  UnsuccessfulTouches  TotalTackles  \\\nTeam                                                                            \nFluminense      14         3             4                   14            18   \nInter           15         3             8                    9            13   \n\n            Interceptions  Clearances  BlockedShots  Fouls  \nTeam                                                        \nFluminense             11          41             2     16  \nInter                   6           8             1     15  \n\n\n\n# Salvando estatísticas por time\nestatisticas_times.to_csv('estatisticas_times_agregadas.csv')\nprint(\"✓ Estatísticas por time salvas como 'estatisticas_times_agregadas.csv'\")\n\n# Estatísticas descritivas\nprint(f\"\\nEstatísticas descritivas:\")\nprint(estatisticas_times.describe())\n\n✓ Estatísticas por time salvas como 'estatisticas_times_agregadas.csv'\n\nEstatísticas descritivas:\n       NumJogadores  IdadeMedia  RatingMedio       PA%      Shots  ShotsOT  \\\ncount      2.000000    2.000000     2.000000   2.00000   2.000000      2.0   \nmean      15.500000   29.055000     6.580000  74.69000  13.500000      4.0   \nstd        0.707107    2.283955     0.480833  16.02304   3.535534      0.0   \nmin       15.000000   27.440000     6.240000  63.36000  11.000000      4.0   \n25%       15.250000   28.247500     6.410000  69.02500  12.250000      4.0   \n50%       15.500000   29.055000     6.580000  74.69000  13.500000      4.0   \n75%       15.750000   29.862500     6.750000  80.35500  14.750000      4.0   \nmax       16.000000   30.670000     6.920000  86.02000  16.000000      4.0   \n\n       KeyPasses  AerialsWon     Touches      Passes    Crosses  AccCrosses  \\\ncount   2.000000    2.000000    2.000000    2.000000   2.000000    2.000000   \nmean    9.000000   14.000000  566.500000  373.500000  17.500000    4.500000   \nstd     2.828427    5.656854  173.241161  188.797511  13.435029    0.707107   \nmin     7.000000   10.000000  444.000000  240.000000   8.000000    4.000000   \n25%     8.000000   12.000000  505.250000  306.750000  12.750000    4.250000   \n50%     9.000000   14.000000  566.500000  373.500000  17.500000    4.500000   \n75%    10.000000   16.000000  627.750000  440.250000  22.250000    4.750000   \nmax    11.000000   18.000000  689.000000  507.000000  27.000000    5.000000   \n\n       LongBalls  AccLongBalls  ThroughBalls  AccThroughBalls  Dribbles  \\\ncount   2.000000      2.000000      2.000000              2.0  2.000000   \nmean   41.000000     19.500000      1.000000              0.0  5.000000   \nstd     8.485281      3.535534      1.414214              0.0  1.414214   \nmin    35.000000     17.000000      0.000000              0.0  4.000000   \n25%    38.000000     18.250000      0.500000              0.0  4.500000   \n50%    41.000000     19.500000      1.000000              0.0  5.000000   \n75%    44.000000     20.750000      1.500000              0.0  5.500000   \nmax    47.000000     22.000000      2.000000              0.0  6.000000   \n\n          Fouled  Offsides  Dispossessed  UnsuccessfulTouches  TotalTackles  \\\ncount   2.000000       2.0      2.000000             2.000000      2.000000   \nmean   14.500000       3.0      6.000000            11.500000     15.500000   \nstd     0.707107       0.0      2.828427             3.535534      3.535534   \nmin    14.000000       3.0      4.000000             9.000000     13.000000   \n25%    14.250000       3.0      5.000000            10.250000     14.250000   \n50%    14.500000       3.0      6.000000            11.500000     15.500000   \n75%    14.750000       3.0      7.000000            12.750000     16.750000   \nmax    15.000000       3.0      8.000000            14.000000     18.000000   \n\n       Interceptions  Clearances  BlockedShots      Fouls  \ncount       2.000000    2.000000      2.000000   2.000000  \nmean        8.500000   24.500000      1.500000  15.500000  \nstd         3.535534   23.334524      0.707107   0.707107  \nmin         6.000000    8.000000      1.000000  15.000000  \n25%         7.250000   16.250000      1.250000  15.250000  \n50%         8.500000   24.500000      1.500000  15.500000  \n75%         9.750000   32.750000      1.750000  15.750000  \nmax        11.000000   41.000000      2.000000  16.000000"
  },
  {
    "objectID": "notebook.html#criação-da-tabela-fato-para-análise-de-correspondência",
    "href": "notebook.html#criação-da-tabela-fato-para-análise-de-correspondência",
    "title": "Análise de Correspondência - Consolidação de Estatísticas de Futebol",
    "section": "5. Criação da Tabela Fato para Análise de Correspondência",
    "text": "5. Criação da Tabela Fato para Análise de Correspondência\nVamos criar diferentes versões da tabela fato para análise de correspondência.\n\n# Versão 1: Tabela fato completa (todas as estatísticas numéricas)\ntabela_fato_completa = estatisticas_times.copy()\n\n# Removendo colunas não adequadas para análise de correspondência\ncolunas_remover = ['NumJogadores', 'IdadeMedia', 'RatingMedio']\nif 'PA%' in tabela_fato_completa.columns:\n    colunas_remover.append('PA%')\n\ntabela_fato_completa = tabela_fato_completa.drop(columns=[col for col in colunas_remover\n                                                          if col in tabela_fato_completa.columns])\n\nprint(\"=== TABELA FATO COMPLETA ===\")\nprint(f\"Dimensões: {tabela_fato_completa.shape}\")\nprint(f\"Estatísticas incluídas: {list(tabela_fato_completa.columns)}\")\nprint(f\"\\nTabela fato completa:\")\nprint(tabela_fato_completa)\n\n=== TABELA FATO COMPLETA ===\nDimensões: (2, 22)\nEstatísticas incluídas: ['Shots', 'ShotsOT', 'KeyPasses', 'AerialsWon', 'Touches', 'Passes', 'Crosses', 'AccCrosses', 'LongBalls', 'AccLongBalls', 'ThroughBalls', 'AccThroughBalls', 'Dribbles', 'Fouled', 'Offsides', 'Dispossessed', 'UnsuccessfulTouches', 'TotalTackles', 'Interceptions', 'Clearances', 'BlockedShots', 'Fouls']\n\nTabela fato completa:\n            Shots  ShotsOT  KeyPasses  AerialsWon  Touches  Passes  Crosses  \\\nTeam                                                                          \nFluminense     11        4          7          10      444     240        8   \nInter          16        4         11          18      689     507       27   \n\n            AccCrosses  LongBalls  AccLongBalls  ThroughBalls  \\\nTeam                                                            \nFluminense           4         47            17             0   \nInter                5         35            22             2   \n\n            AccThroughBalls  Dribbles  Fouled  Offsides  Dispossessed  \\\nTeam                                                                    \nFluminense                0         4      14         3             4   \nInter                     0         6      15         3             8   \n\n            UnsuccessfulTouches  TotalTackles  Interceptions  Clearances  \\\nTeam                                                                       \nFluminense                   14            18             11          41   \nInter                         9            13              6           8   \n\n            BlockedShots  Fouls  \nTeam                             \nFluminense             2     16  \nInter                  1     15  \n\n\n\n# Versão 2: Tabela fato simplificada (categorias principais)\nprint(\"=== CRIANDO TABELA FATO SIMPLIFICADA ===\")\n\n# Definindo categorias principais\ncategorias = {}\n\n# Estatísticas ofensivas\nif all(col in tabela_fato_completa.columns for col in ['Shots', 'ShotsOT', 'Dribbles']):\n    categorias['Ataque'] = tabela_fato_completa['Shots'] + \\\n        tabela_fato_completa['ShotsOT'] + tabela_fato_completa['Dribbles']\n\n# Estatísticas de passe\nif all(col in tabela_fato_completa.columns for col in ['Passes', 'Crosses', 'LongBalls']):\n    categorias['Passe'] = tabela_fato_completa['Passes'] + \\\n        tabela_fato_completa['Crosses'] + tabela_fato_completa['LongBalls']\n\n# Estatísticas defensivas\ncolunas_defesa = ['TotalTackles',\n                  'Interceptions', 'Clearances', 'BlockedShots']\ncolunas_defesa_disponiveis = [\n    col for col in colunas_defesa if col in tabela_fato_completa.columns]\nif colunas_defesa_disponiveis:\n    categorias['Defesa'] = tabela_fato_completa[colunas_defesa_disponiveis].sum(\n        axis=1)\n\n# Controle de jogo\nif 'Touches' in tabela_fato_completa.columns:\n    categorias['ControleBola'] = tabela_fato_completa['Touches']\n\n# Disciplina\nif 'Fouls' in tabela_fato_completa.columns:\n    categorias['Faltas'] = tabela_fato_completa['Fouls']\n\n# Criando tabela simplificada\ntabela_fato_simplificada = pd.DataFrame(\n    categorias, index=tabela_fato_completa.index)\n\nprint(f\"Categorias criadas: {list(categorias.keys())}\")\nprint(f\"\\nTabela fato simplificada:\")\nprint(tabela_fato_simplificada)\n\n=== CRIANDO TABELA FATO SIMPLIFICADA ===\nCategorias criadas: ['Ataque', 'Passe', 'Defesa', 'ControleBola', 'Faltas']\n\nTabela fato simplificada:\n            Ataque  Passe  Defesa  ControleBola  Faltas\nTeam                                                   \nFluminense      19    295      72           444      16\nInter           26    569      28           689      15\n\n\n\n# Salvando as tabelas fato\ntabela_fato_completa.to_csv('tabela_fato_correspondencia_completa.csv')\ntabela_fato_simplificada.to_csv('tabela_fato_correspondencia_simplificada.csv')\n\nprint(\"✓ Tabela fato completa salva como 'tabela_fato_correspondencia_completa.csv'\")\nprint(\"✓ Tabela fato simplificada salva como 'tabela_fato_correspondencia_simplificada.csv'\")\n\n✓ Tabela fato completa salva como 'tabela_fato_correspondencia_completa.csv'\n✓ Tabela fato simplificada salva como 'tabela_fato_correspondencia_simplificada.csv'"
  },
  {
    "objectID": "notebook.html#visualizações-exploratórias",
    "href": "notebook.html#visualizações-exploratórias",
    "title": "Análise de Correspondência - Consolidação de Estatísticas de Futebol",
    "section": "6. Visualizações Exploratórias",
    "text": "6. Visualizações Exploratórias\nVamos criar algumas visualizações para entender melhor os dados.\n\n# Configuração de visualização\nplt.style.use('default')\nplt.rcParams['figure.figsize'] = (12, 8)\n\n# Heatmap da tabela fato completa\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n\n# Heatmap completa\nsns.heatmap(tabela_fato_completa.T, annot=True,\n            cmap='YlOrRd', fmt='.0f', ax=ax1)\nax1.set_title('Estatísticas Completas por Time', fontsize=14, pad=20)\nax1.set_xlabel('Times', fontsize=12)\nax1.set_ylabel('Estatísticas', fontsize=12)\n\n# Heatmap simplificada\nsns.heatmap(tabela_fato_simplificada.T, annot=True,\n            cmap='viridis', fmt='.0f', ax=ax2)\nax2.set_title('Categorias Principais por Time', fontsize=14, pad=20)\nax2.set_xlabel('Times', fontsize=12)\nax2.set_ylabel('Categorias', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Comparação entre times - categorias principais\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\naxes = axes.flatten()\n\ncores = ['#FF6B6B', '#4ECDC4']  # Cores para os times\n\nfor i, categoria in enumerate(tabela_fato_simplificada.columns):\n    if i &lt; len(axes):\n        valores = tabela_fato_simplificada[categoria]\n        ax = axes[i]\n\n        bars = ax.bar(valores.index, valores.values,\n                      color=cores[:len(valores)])\n        ax.set_title(f'{categoria}', fontsize=12, fontweight='bold')\n        ax.set_ylabel('Total', fontsize=10)\n\n        # Adicionando valores nas barras\n        for bar, valor in zip(bars, valores.values):\n            height = bar.get_height()\n            ax.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n                    f'{int(valor)}', ha='center', va='bottom', fontweight='bold')\n\n# Removendo eixos não utilizados\nfor i in range(len(tabela_fato_simplificada.columns), len(axes)):\n    axes[i].remove()\n\nplt.suptitle('Comparação entre Times - Estatísticas Principais',\n             fontsize=16, fontweight='bold', y=0.98)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebook.html#análise-comparativa-entre-times",
    "href": "notebook.html#análise-comparativa-entre-times",
    "title": "Análise de Correspondência - Consolidação de Estatísticas de Futebol",
    "section": "7. Análise Comparativa entre Times",
    "text": "7. Análise Comparativa entre Times\nVamos fazer uma análise comparativa detalhada entre os times.\n\n# Análise comparativa detalhada\nprint(\"=== ANÁLISE COMPARATIVA ENTRE TIMES ===\")\n\ntimes = tabela_fato_simplificada.index.tolist()\nprint(f\"Times analisados: {times}\")\n\n# Calculando diferenças percentuais\nif len(times) == 2:\n    time1, time2 = times[0], times[1]\n\n    print(f\"\\n{time1} vs {time2}:\")\n    print(\"-\" * 50)\n\n    for categoria in tabela_fato_simplificada.columns:\n        val1 = tabela_fato_simplificada.loc[time1, categoria]\n        val2 = tabela_fato_simplificada.loc[time2, categoria]\n\n        if val2 != 0:\n            diff_perc = ((val1 - val2) / val2) * 100\n            maior = time1 if val1 &gt; val2 else time2\n\n            print(\n                f\"{categoria:15s}: {time1} {val1:6.0f} | {time2} {val2:6.0f} | Vantagem: {maior} ({abs(diff_perc):5.1f}%)\")\n        else:\n            print(\n                f\"{categoria:15s}: {time1} {val1:6.0f} | {time2} {val2:6.0f} | Sem comparação possível\")\n\n=== ANÁLISE COMPARATIVA ENTRE TIMES ===\nTimes analisados: ['Fluminense', 'Inter']\n\nFluminense vs Inter:\n--------------------------------------------------\nAtaque         : Fluminense     19 | Inter     26 | Vantagem: Inter ( 26.9%)\nPasse          : Fluminense    295 | Inter    569 | Vantagem: Inter ( 48.2%)\nDefesa         : Fluminense     72 | Inter     28 | Vantagem: Fluminense (157.1%)\nControleBola   : Fluminense    444 | Inter    689 | Vantagem: Inter ( 35.6%)\nFaltas         : Fluminense     16 | Inter     15 | Vantagem: Fluminense (  6.7%)\n\n\n\n# Criando um radar chart para comparação visual\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ndef criar_radar_chart(dados, times, titulo):\n    # Número de variáveis\n    num_vars = len(dados.columns)\n\n    # Ângulos para cada eixo\n    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n    angles += angles[:1]  # Completar o círculo\n\n    # Criar figura\n    fig, ax = plt.subplots(\n        figsize=(10, 10), subplot_kw=dict(projection='polar'))\n\n    # Cores para cada time\n    cores = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n\n    # Plotar dados para cada time\n    for i, time in enumerate(times):\n        valores = dados.loc[time].tolist()\n        valores += valores[:1]  # Completar o círculo\n\n        ax.plot(angles, valores, 'o-', linewidth=2, label=time, color=cores[i])\n        ax.fill(angles, valores, alpha=0.25, color=cores[i])\n\n    # Configurar eixos\n    ax.set_xticks(angles[:-1])\n    ax.set_xticklabels(dados.columns)\n    ax.set_ylim(0, dados.values.max() * 1.1)\n\n    # Adicionar título e legenda\n    plt.title(titulo, size=16, fontweight='bold', pad=20)\n    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n\n    return fig\n\n\n# Normalizar dados para o radar chart (0-100)\ndados_normalizados = tabela_fato_simplificada.copy()\nfor col in dados_normalizados.columns:\n    max_val = dados_normalizados[col].max()\n    if max_val &gt; 0:\n        dados_normalizados[col] = (dados_normalizados[col] / max_val) * 100\n\n# Criar radar chart\nif len(times) &gt; 0:\n    fig = criar_radar_chart(dados_normalizados, times,\n                            'Comparação de Desempenho entre Times')\n    plt.show()"
  },
  {
    "objectID": "notebook.html#resumo-e-arquivos-gerados",
    "href": "notebook.html#resumo-e-arquivos-gerados",
    "title": "Análise de Correspondência - Consolidação de Estatísticas de Futebol",
    "section": "8. Resumo e Arquivos Gerados",
    "text": "8. Resumo e Arquivos Gerados\nVamos fazer um resumo final e listar todos os arquivos gerados.\n\n# Verificando arquivos gerados\nimport os\n\narquivos_gerados = [\n    'estatisticas_jogadores_consolidada.csv',\n    'estatisticas_times_agregadas.csv',\n    'tabela_fato_correspondencia_completa.csv',\n    'tabela_fato_correspondencia_simplificada.csv'\n]\n\nprint(\"=== RESUMO DOS ARQUIVOS GERADOS ===\")\nprint()\n\nfor arquivo in arquivos_gerados:\n    if os.path.exists(arquivo):\n        # Carregar para mostrar dimensões\n        df = pd.read_csv(arquivo)\n        print(f\"✓ {arquivo}\")\n        print(f\"   Dimensões: {df.shape}\")\n        print(f\"   Colunas: {df.shape[1]}\")\n        print()\n    else:\n        print(f\"✗ {arquivo} - NÃO ENCONTRADO\")\n        print()\n\n=== RESUMO DOS ARQUIVOS GERADOS ===\n\n✓ estatisticas_jogadores_consolidada.csv\n   Dimensões: (31, 28)\n   Colunas: 28\n\n✓ estatisticas_times_agregadas.csv\n   Dimensões: (2, 27)\n   Colunas: 27\n\n✓ tabela_fato_correspondencia_completa.csv\n   Dimensões: (2, 23)\n   Colunas: 23\n\n✓ tabela_fato_correspondencia_simplificada.csv\n   Dimensões: (2, 6)\n   Colunas: 6\n\n\n\n\n# Resumo final das análises\nprint(\"=== RESUMO FINAL ===\")\nprint()\nprint(\"1. CONSOLIDAÇÃO DE DADOS:\")\nprint(f\"   • {len(datasets)} datasets originais consolidados\")\nprint(f\"   • {len(colunas_duplicadas)} colunas duplicadas identificadas e tratadas\")\nprint(f\"   • {estatisticas_jogadores.shape[0]} jogadores consolidados\")\nprint(f\"   • {estatisticas_jogadores.shape[1]} estatísticas por jogador\")\nprint()\n\nprint(\"2. AGREGAÇÃO POR TIME:\")\nprint(f\"   • {len(times)} times analisados\")\nprint(\n    f\"   • {tabela_fato_completa.shape[1]} estatísticas agregadas (versão completa)\")\nprint(\n    f\"   • {tabela_fato_simplificada.shape[1]} categorias principais (versão simplificada)\")\nprint()\n\nprint(\"3. TABELAS PARA ANÁLISE DE CORRESPONDÊNCIA:\")\nprint(\"   • Tabela completa: matriz times x todas as estatísticas\")\nprint(\"   • Tabela simplificada: matriz times x categorias principais\")\nprint(\"   • Ambas prontas para análise de correspondência\")\nprint()\n\nprint(\"4. PRÓXIMOS PASSOS RECOMENDADOS:\")\nprint(\"   • Use 'tabela_fato_correspondencia_simplificada.csv' para análise inicial\")\nprint(\"   • Use 'tabela_fato_correspondencia_completa.csv' para análise detalhada\")\nprint(\"   • Aplique técnicas de análise de correspondência (CA)\")\nprint(\"   • Interprete os resultados considerando o contexto do jogo\")\n\n=== RESUMO FINAL ===\n\n1. CONSOLIDAÇÃO DE DADOS:\n   • 4 datasets originais consolidados\n   • 9 colunas duplicadas identificadas e tratadas\n   • 31 jogadores consolidados\n   • 28 estatísticas por jogador\n\n2. AGREGAÇÃO POR TIME:\n   • 2 times analisados\n   • 22 estatísticas agregadas (versão completa)\n   • 5 categorias principais (versão simplificada)\n\n3. TABELAS PARA ANÁLISE DE CORRESPONDÊNCIA:\n   • Tabela completa: matriz times x todas as estatísticas\n   • Tabela simplificada: matriz times x categorias principais\n   • Ambas prontas para análise de correspondência\n\n4. PRÓXIMOS PASSOS RECOMENDADOS:\n   • Use 'tabela_fato_correspondencia_simplificada.csv' para análise inicial\n   • Use 'tabela_fato_correspondencia_completa.csv' para análise detalhada\n   • Aplique técnicas de análise de correspondência (CA)\n   • Interprete os resultados considerando o contexto do jogo"
  },
  {
    "objectID": "notebook.html#conclusão",
    "href": "notebook.html#conclusão",
    "title": "Análise de Correspondência - Consolidação de Estatísticas de Futebol",
    "section": "Conclusão",
    "text": "Conclusão\nO processo de consolidação foi concluído com sucesso!\n\nArquivos Gerados:\n\nestatisticas_jogadores_consolidada.csv - Todas as estatísticas por jogador (sem duplicatas)\nestatisticas_times_agregadas.csv - Estatísticas agregadas por time\ntabela_fato_correspondencia_completa.csv - Matriz completa para análise de correspondência\ntabela_fato_correspondencia_simplificada.csv - Matriz simplificada com categorias principais\n\n\n\nPara Análise de Correspondência:\n\nLinhas: Times (Inter, Fluminense)\n\nColunas: Estatísticas/Categorias de jogo\nValores: Totais agregados por time\n\nAs tabelas estão prontas para análise de correspondência usando bibliotecas como prince, sklearn ou ca em R."
  },
  {
    "objectID": "CA.html",
    "href": "CA.html",
    "title": "Analise de correspondencia",
    "section": "",
    "text": "Estágio 1: Objetivos da CA Os pesquisadores são constantemente confrontados com a necessidade de quantificar os dados qualitativos encontrados em variáveis nominais. A CA difere de outras técnicas MDS em sua habilidade de acomodar tanto dados nãométricos quanto relações não-lineares. Ela faz redução dimensional semelhante a escalonamento multidimensional e um tipo de mapeamento perceptual no qual as categorias são representadas no espaço multidimensional. A proximidade indica o nível de associação entre as categorias linha ou coluna. A CA pode satisfazer qualquer um dos dois objetivos básicos: 1. Associação entre somente categorias de linha ou de coluna. A CA pode ser usada para examinar a associação entre as categorias de apenas uma linha ou coluna. Um uso comum é o exame das categorias de uma escala, como a escala Likert (cinco categorias que variam de “concordo plenamente” a “discordo plenamente”) ou outras escalas qualitativas (p.ex., excelente, bom, regular, ruim). As categorias podem ser comparadas para ver se duas podem ser combinadas (isto é, elas estão muito próximas no mapa) ou se fornecem discriminação (ou seja, estão localizadas separadamente no espaço perceptual). 2. Associação entre categorias de linha e coluna. Nesta aplicação, o interesse repousa na representação da associação entre categorias das linhas e colunas, como nosso exemplo de vendas de produto por faixa etária. Esse uso é mais semelhante ao exemplo anterior de MDS e tem impelido a CA a um uso mais amplo em diversas áreas de pesquisa. O pesquisador deve determinar os objetivos específicos da análise, porque certas decisões são baseadas em qual tipo de objetivo é escolhido. A CA fornece uma representação multivariada de interdependência para dados não-métricos que não é possível com outros métodos. Com uma técnica composicional, o pesquisador deve garantir que todas as variáveis relevantes adequadas à Dimensão II Produto B Dimensão I Meia-Idade Idoso Jovens adultos Produto A Produto C FIGURA 9-11 Mapa perceptual da análise de correspondência. Análise Multivariada de Dados 512 questão de pesquisa tenham sido incluídas. Isso está em contraste com os procedimentos decomposicionais MDS descritos anteriormente, os quais exigem apenas a medida geral de similaridade. Estágio 2: Projeto de pesquisa de CA A análise de correspondência exige apenas uma matriz retangular* de dados (tabulação cruzada) de entradas não-negativas. O tipo mais comum de matriz de entrada é uma tabela de contingência com categorias específicas definindo as linhas e colunas. Ao se criar a tabela, surgem diversas questões, relativas à natureza das variáveis e categorias compreendendo linhas e colunas: 1. As linhas e colunas não têm significados pré-definidos (ou seja, os atributos não têm que ser sempre linhas e assim por diante), mas, em vez disso, representam as respostas a uma ou mais variáveis categóricas. As categorias nas linhas e colunas, porém, devem ter um significado específico para fins de interpretação. 2. As categorias para uma linha ou coluna não precisam ser uma só variável, mas podem representar qualquer conjunto de relações. Um primeiro exemplo é o método “escolha qualquer um” [14, 15], no qual é dado aos respondentes um conjunto de objetos e características. Os respondentes então indicam quais objetos, se houver algum, são descritos pelas características. O respondente pode escolher qualquer número de objetos para cada característica, e a tabela de tabulação cruzada é o número total de vezes em que cada objeto foi descrito por cada característica. 3. A tabulação cruzada pode ocorrer para mais de duas variáveis em uma forma matricial multivariada. Em tais casos, a análise de correspondência múltipla é empregada. Em um procedimento muito semelhante à análise bivariada, as variáveis adicionais são ajustadas de forma que todas as categorias são colocadas no mesmo espaço multidimensional. A natureza generalizada dos tipos de relações que podem ser retratadas na tabela de contingência torna a CA uma técnica amplamente aplicável. Seu uso crescente nos últimos anos é um resultado direto do contínuo desenvolvimento de abordagens que usam este formato para analisar novos tipos de relações. Estágio 3: Suposições em CA A análise de correspondência compartilha com as técnicas mais tradicionais de MDS uma relativa liberdade de pressupostos. O uso de dados estritamente não-métricos em sua forma mais simples (dados tabulados cruzados) representa as relações lineares e não-lineares igualmente bem. A falta de suposições, porém, não deve fazer com que o pesquisador negligencie os esforços para garantir a comparabilidade de objetos e, como essa é uma técnica composicional, a completude dos atributos usados. Estágio 4: Determinação dos resultados da CA e avaliação do ajuste geral Com uma tabela de dados cruzados, as freqüências para qualquer combinação de categorias de linhas-colunas são relacionadas com outras combinações com base nas freqüências marginais. Como descrito em nosso exemplo anterior, a análise de correspondência usa essa relação básica em três passos para criar um mapa perceptual: 1. Calcula uma expectativa condicional (a freqüência esperada de célula) que representa a similaridade ou associação entre categorias de linha e coluna. 2. Uma vez obtidas, computam-se as diferenças entre as freqüências reais e esperadas e converte-se as mesmas a uma medida padronizada (qui-quadrado). Usando-se esses resultados como uma métrica de distâncias, torna-se os mesmos comparáveis com as matrizes de entrada usadas nas abordagens MDS já discutidas. 3. Através de um processo muito parecido com o escalonamento multidimensional, cria-se uma série de soluções dimensionais (unidimensional, bidimensional etc.) sempre que possível. As dimensões relacionam simultaneamente as linhas e colunas em um único gráfico conjunto. O resultado é uma representação de categorias de linhas e/ou colunas (p.ex., marcas e atributos) no mesmo gráfico. Determinação do impacto de células individuais Deve ser observado que os dois termos específicos, desenvolvidos em análise de correspondência, descrevem as propriedades dos valores de freqüência e sua contribuição relativa à análise. • O primeiro termo é massa, que é primeiramente definido para qualquer entrada individual na tabulação cruzada como o percentual do total representado por aquela entrada. É calculado como o valor de qualquer entrada dividido por N (o total para a tabela, que é a soma das linhas ou colunas). Assim, a soma de todas as entradas da tabela (células) é igual a 1,0. Também podemos calcular a massa de qualquer categoria de linha ou coluna, somando ao longo de todas as entradas. Tal resultado representa a contribuição de qualquer categoria de linha ou coluna para a massa total. • A segunda medida é inércia, que é definida como o quiquadrado total dividido por N (o total das contagens de freqüência). Deste modo temos uma medida relativa de quiquadrado que pode ser relacionada com qualquer contagem de freqüência. Com essas semelhanças com MDS surge um conjunto parecido de problemas, centrados em duas questões fundamentais na avaliação de ajuste geral: avaliação da importância relativa das dimensões, e então a identificação do número apropriado de dimensões. Cada um desses aspectos é discutido na próxima seção. Avaliação do número de dimensões Autovalores, também conhecidos como valores singulares, são obtidos para cada dimensão e indicam a contribuição relativa de cada dimensão na explicação da variância * N. de R. T.: Seria mais adequada a expressão “de dupla entrada”, tendo em vista que tal matriz pode também ser quadrada, quando linhas e colunas apresentam o mesmo número de categorias. 513 CAPÍTULO 9 Escalonamento Multidimensional e Análise de Correspondência nas categorias. Semelhante à análise fatorial, podemos determinar a quantia de variância explicada tanto para dimensões individuais quanto para a solução como um todo. Alguns programas, como os de SPSS, introduzem uma medida chamada de inércia, que também mede variação explicada e está diretamente relacionada com o autovalor. Determinação do número de dimensões O número máximo de dimensões que pode ser estimado é um a menos do que o menor número entre a quantia de linhas ou de colunas. Por exemplo, com seis colunas e oito linhas, o número máximo de dimensões seria cinco, o que corresponde a seis (o número de colunas) menos um. O pesquisador seleciona o número de dimensões com base no nível geral de variância explicada desejada e na explicação extra ganha pelo acréscimo de uma outra dimensão. Ao avaliar dimensionalidade, o pesquisador está diante de negociações muito parecidas com outras soluções MDS ou mesmo de análise fatorial (Capítulo 3): • Cada dimensão adicionada à solução aumenta a variância explicada da solução, mas em uma quantia decrescente (ou seja, a primeira dimensão explica a maior parte da variância, a segunda explica a segunda maior parte, e assim por diante). • Adicionar dimensões aumenta a complexidade do processo de interpretação; mapas perceptuais com mais de três dimensões se tornam cada vez mais complexos para análise. O pesquisador deve equilibrar o desejo por variância explicada maior versus a solução mais complexa que possa afetar a interpretação. Uma dica prática é que dimensões com inércia (autovalores) maiores que 0,2 devem ser incluídas na análise. Estimação do modelo Vários programas de computador estão à disposição para realizar a análise de correspondência. Entre os programas mais populares, estão ANACOR e HOMALS, disponíveis no SPSS; CA de BMDP; CORRAN e CORRESP de PC-MDS [24]; e MAPWISE [21]. Um grande número de aplicações especializadas tem surgido em disciplinas específicas como ecologia, geologia e muitas das ciências sociais. Estágio 5: Interpretação dos resultados Logo que a dimensionalidade tiver sido estabelecida, o pesquisador se defronta com duas tarefas: interpretar as dimensões para compreender a base para a associação entre categorias e avaliar o grau de associação entre categorias, dentro de uma linha/coluna ou entre linhas e colunas. Fazendo isso, o pesquisador ganha uma compreensão a respeito das dimensões inerentes sobre as quais o mapa perceptual se baseia, juntamente com a associação derivada de qualquer conjunto específico de categorias. Definição do caráter das dimensões Se o pesquisador está interessado em definir o caráter de uma ou mais dimensões em termos das categorias de linha ou coluna, medidas descritivas em cada programa de computador indicam a associação de cada categoria a uma dimensão específica. Por exemplo, em SPSS a medida de inércia (usada para avaliar o grau de variância explicada) é decomposta ao longo das dimensões. Semelhantes, em caráter, a cargas fatoriais, esses valores representam a extensão da associação para cada categoria individualmente com cada dimensão. O pesquisador pode então nomear cada dimensão em termos das categorias mais associadas com ela. Além de representar a associação de cada categoria com cada dimensão, os valores de inércia podem ser totalizados ao longo de dimensões em uma medida coletiva. Fazendo isso, ganhamos uma medida empírica do grau em que cada categoria está representada ao longo de todas as dimensões. Conceitualmente, esta medida é similar à medida de comunalidade de análise fatorial (ver Capítulo 3). Avaliação da associação entre categorias A segunda tarefa na interpretação é identificar a associação de uma categoria com outras, o que pode ser feito visualmente ou por meio de medidas empíricas. Qualquer que seja a técnica empregada, o pesquisador deve primeiramente escolher os tipos de comparação a serem feitas e então a normalização adequada para a comparação selecionada. Os dois tipos de comparação são: 1. Entre categorias da mesma linha ou coluna. Aqui o foco é apenas sobre linhas ou colunas, como quando se examinam as categorias de uma escala para ver se elas podem ser combinadas. Esses tipos de comparações podem ser feitos diretamente a partir de qualquer análise de correspondência. 2. Entre linhas e colunas. Uma tentativa de relacionar a associação entre uma categoria de linha e uma de coluna. Este tipo mais comum de comparação relaciona categorias ao longo de dimensões (como em nosso exemplo anterior, vendas de produtos associadas com categorias etárias). Contudo, desta vez há algum debate na adequação da comparação entre categorias de linha e de coluna. Em um sentido estrito, distâncias entre pontos representando categorias só podem ser feitas dentro de uma linha ou coluna. É considerada inadequada a comparação direta de uma categoria de linha e uma de coluna. É apropriado fazer generalizações referentes às dimensões e à posição de cada categoria sobre tais dimensões. Assim, a posição relativa de categorias de linha e coluna pode ser definida dentro dessas dimensões, mas não deve haver comparação direta. Alguns programas de computador fornecem um procedimento de normalização para viabilizar essa comparação direta. Se apenas um procedimento de normalização de linha ou coluna está disponível, técnicas alternativas são propostas para tornar todas as categorias comparáveis [2, 21], mas ainda há discordâncias quanto ao seu sucesso [12]. Nos casos em que as comparações diretas não são possíveis, a Análise Multivariada de Dados 514 correspondência geral ainda vale e padrões específicos podem ser distinguidos. Os objetivos da pesquisa podem se concentrar na avaliação das dimensões ou na comparação de categorias, e o pesquisador é encorajado a fazer ambas as interpretações já que elas reforçam uma a outra. Por exemplo, a comparação de categorias de linha versus de coluna sempre pode ser complementada com a compreensão da natureza das dimensões para fornecer uma perspectiva mais abrangente do posicionamento das categorias em vez de simplesmente comparações específicas. Analogamente, a avaliação da comparação específica de categorias pode dar especificidade à interpretação das dimensões. Estágio 6: Validação dos resultados A natureza composicional da análise de correspondência fornece maior especificidade para o pesquisador validar os resultados. Fazendo isso, o pesquisador deve buscar avaliar duas questões-chave relativas à generalidade de dois elementos: • Amostra. Como ocorre com todas as técnicas MDS, deve-se enfatizar a garantia da generalidade por meio de análises de subamostras ou múltiplas amostras. • Objetos. A generalidade dos objetos (representada individualmente e como um conjunto pelas categorias) também deve ser estabelecida. A sensibilidade dos resultados à adição ou eliminação de uma categoria pode ser avaliada. A meta é avaliar se a análise depende de apenas poucos objetos e/ou atributos. Em qualquer caso, o pesquisador deve entender o verdadeiro significado dos resultados em termos das categorias sendo analisadas. A natureza inferencial da análise de correspondência, como outros métodos MDS, requer estrita confiança na representatividade e generalidade da amostra de respondentes e objetos (categorias) sob análise. Visão geral da análise de correspondência A análise de correspondência apresenta ao pesquisador diversas vantagens, variando da natureza generalizada dos dados de entrada ao desenvolvimento de mapas perceptuais únicos: • A simples tabulação cruzada de múltiplas variáveis categóricas, como atributos de produtos versus marcas, pode ser representada em um espaço perceptual. Essa abordagem permite ao pesquisador analisar as respostas existentes ou reunir respostas no tipo menos restritivo de medida, o nível categórico ou nominal. Por exemplo, o respondente precisa avaliar somente com respostas do tipo sim ou não um conjunto de objetos quanto a alguns atributos. Essas respostas podem então ser agregadas em uma tabela cruzada e analisadas. Outras técnicas, como a análise fatorial, exigem avaliações na escala intervalar de cada atributo para cada objeto. • A CA retrata não somente as relações entre as linhas e colunas, mas também as relações entre as categorias de linhas ou colunas. Por exemplo, se as colunas fossem atributos, múltiplos atributos próximos teriam perfis similares ao longo de produtos, formando um grupo de atributos muito semelhante a um fator de análise de componentes principais. • A CA pode fornecer uma visão conjunta de categorias das linhas e colunas na mesma dimensionalidade. Certas modificações de programas permitem comparações entre pontos nos quais a proximidade relativa está diretamente relacionada com a maior associação entre pontos separados [1, 21]. Quando essas comparações são possíveis, permitem que categorias das linhas e colunas sejam examinadas simultaneamente. Uma análise desse tipo capacitaria o pesquisador a identificar grupos de produtos caracterizados por atributos em grande proximidade. Junto com as vantagens da CA, porém, surgem algumas desvantagens ou limitações. • A técnica é descritiva e nada adequada ao teste de hipóteses. Se a relação quantitativa de categorias é desejada, métodos como modelos log-lineares são sugeridos. A CA é mais adequada à análise exploratória de dados. • A CA, como acontece com muitos métodos de redução de dimensionalidade, não dispõe de procedimento para determinar conclusivamente o número apropriado de dimensões. Como ocorre com métodos similares, o pesquisador deve equilibrar interpretabilidade com parcimônia da representação dos dados. Análise de correspondência • A análise de correspondência (CA) é mais adequada para pesquisa exploratória e não é adequada para teste de hipóteses • A CA é uma forma de técnica composicional que demanda especificação de objetos e atributos a serem comparados • A análise de correspondência é sensível a observações atípicas, as quais devem ser eliminadas antes de se usar tal técnica • O número de dimensões a serem mantidas na solução se baseia em: • Dimensões com inércia (autovalores) maiores que 0,2 • Dimensões suficientes para atender os objetivos da pesquisa (geralmente duas ou três) • Dimensões podem ser “nomeadas” com base na decomposição de medidas de inércia ao longo de uma dimensão: • Esses valores mostram a extensão de associação para cada categoria individualmente com cada dimensão • Elas podem ser usadas para descrição como as cargas em análise fatorial REGRAS PRÁTICAS 9-4 515 CAPÍTULO 9 Escalonamento Multidimensional e Análise de Correspondência • A técnica é bastante sensível a dados atípicos, em termos de linhas ou colunas (p.ex., atributos ou marcas). Além disso, para fins de generalização, o problema de objetos ou atributos omitidos é crítico. No geral, a análise de correspondência provê uma valiosa ferramenta analítica para um tipo de dado (não-métrico) que normalmente não é o ponto focal de técnicas multivariadas. A análise de correspondência também fornece ao pesquisador uma técnica composicional complementar ao MDS, para tratar de questões nas quais a comp"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análise de Correspondência: Fluminense vs Inter de Milão",
    "section": "",
    "text": "Este documento apresenta uma Análise de Correspondência (CA) aplicada às estatísticas de jogadores do Fluminense e Inter de Milão. A técnica de CA é particularmente útil para analisar dados categóricos e explorar relações entre variáveis qualitativas.\nA análise se baseia nas estatísticas de desempenho dos jogadores, categorizadas de acordo com sua posição em campo e seu time. O objetivo é identificar padrões de associação entre as posições específicas de cada time e suas características de desempenho, representadas por variáveis categóricas derivadas das estatísticas originais."
  },
  {
    "objectID": "index.html#introdução",
    "href": "index.html#introdução",
    "title": "Análise de Correspondência: Fluminense vs Inter de Milão",
    "section": "",
    "text": "Este documento apresenta uma Análise de Correspondência (CA) aplicada às estatísticas de jogadores do Fluminense e Inter de Milão. A técnica de CA é particularmente útil para analisar dados categóricos e explorar relações entre variáveis qualitativas.\nA análise se baseia nas estatísticas de desempenho dos jogadores, categorizadas de acordo com sua posição em campo e seu time. O objetivo é identificar padrões de associação entre as posições específicas de cada time e suas características de desempenho, representadas por variáveis categóricas derivadas das estatísticas originais."
  },
  {
    "objectID": "index.html#carregamento-e-preparação-dos-dados",
    "href": "index.html#carregamento-e-preparação-dos-dados",
    "title": "Análise de Correspondência: Fluminense vs Inter de Milão",
    "section": "Carregamento e Preparação dos Dados",
    "text": "Carregamento e Preparação dos Dados\n\n\nCódigo\n# Carregar pacotes necessários\nlibrary(tidyverse)\nlibrary(FactoMineR)  # Para análise de correspondência\nlibrary(factoextra)  # Para visualização de resultados\nlibrary(ca)          # Pacote alternativo para CA\nlibrary(knitr)       # Para formatação de tabelas\nlibrary(kableExtra)  # Para tabelas mais elaboradas\nlibrary(plotly)      # Para visualizações 3D interativas\n\n# Carregar os dados\ndados &lt;- read.csv(\"estatisticas_jogadores_consolidada.csv\", stringsAsFactors = FALSE)\n\n# Visualizar estrutura dos dados (primeiras linhas)\nkable(head(dados, 5), \n      caption = \"Primeiras 5 linhas do conjunto de dados\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;%\n  scroll_box(width = \"100%\")\n\n\n\n\n\nPrimeiras 5 linhas do conjunto de dados\n\n\nPlayer\nAge\nPosition\nShots\nShotsOT\nKeyPasses\nPA\nAerialsWon\nTouches\nRating\nTeam\nPasses\nCrosses\nAccCrosses\nLongBalls\nAccLongBalls\nThroughBalls\nAccThroughBalls\nDribbles\nFouled\nOffsides\nDispossessed\nUnsuccessfulTouches\nTotalTackles\nInterceptions\nClearances\nBlockedShots\nFouls\n\n\n\n\nYann Sommer\n36\nGK\n0\n0\n0\n96.4\n0\n32\n5.22\nInter\n28\n0\n0\n2\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nMatteo Darmian\n35\nDC\n0\n0\n0\n87.5\n2\n58\n6.24\nInter\n40\n2\n1\n3\n1\n0\n0\n0\n2\n0\n1\n0\n2\n1\n0\n0\n3\n\n\nAlessandro Bastoni\n26\nDC\n0\n0\n0\n84.0\n2\n64\n6.03\nInter\n50\n1\n0\n6\n3\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n2\n\n\nStefan de Vrij\n33\nDC\n2\n0\n0\n90.8\n4\n93\n6.87\nInter\n76\n0\n0\n4\n2\n0\n0\n1\n0\n0\n0\n0\n4\n2\n4\n0\n0\n\n\nDenzel Dumfries\n29\nDMR\n1\n0\n0\n92.9\n0\n22\n5.78\nInter\n14\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n2\n\n\n\n\n\n\n\n\nCódigo\n# Resumo das variáveis principais\nresumo_vars &lt;- data.frame(\n  Variavel = names(dados)[4:15], # Estatísticas principais\n  Minimo = sapply(dados[, 4:15], min, na.rm = TRUE),\n  Media = round(sapply(dados[, 4:15], mean, na.rm = TRUE), 2),\n  Mediana = sapply(dados[, 4:15], median, na.rm = TRUE),\n  Maximo = sapply(dados[, 4:15], max, na.rm = TRUE)\n)\n\nkable(resumo_vars, \n      caption = \"Resumo das principais estatísticas numéricas\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n\nResumo das principais estatísticas numéricas\n\n\n\nVariavel\nMinimo\nMedia\nMediana\nMaximo\n\n\n\n\nShots\nShots\n0\n0.87\n0\n5\n\n\nShotsOT\nShotsOT\n0\n0.26\n0\n2\n\n\nKeyPasses\nKeyPasses\n0\n0.58\n0\n4\n\n\nPA\nPA\n0\n75.06\n82.1\n100\n\n\nAerialsWon\nAerialsWon\n0\n0.90\n0\n4\n\n\nTouches\nTouches\n6\n36.55\n33\n93\n\n\nRating\nRating\n5.22\n6.57\n6.39\n7.89\n\n\nTeam\nTeam\nFluminense\nNA\nInter\nInter\n\n\nPasses\nPasses\n0\n24.10\n20\n76\n\n\nCrosses\nCrosses\n0\n1.13\n1\n6\n\n\nAccCrosses\nAccCrosses\n0\n0.29\n0\n2\n\n\nLongBalls\nLongBalls\n0\n2.65\n1\n18"
  }
]